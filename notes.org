The monadic interpreter is mostly taken from [[http://homepages.inf.ed.ac.uk/wadler/papers/essence/essence.ps][Wadler]].

Other related work:
- [[http://web.cecs.pdx.edu/~mpj/pubs/modinterp.html][Monads Transformers and Modular Interpreters]]
  + [[http://www.cas.mcmaster.ca/~kahl/FP/2003/Interpreter.pdf][Haskell implementation]]
- [[http://www.andres-loeh.de/OpenDatatypes.pdf][Open Data Types and Open Functions]]

* Downsides to the monadic interpreter approach for modularity
** Explicit use of monads
You have to explicitly write the interpreter to return monads instead
of raw values.

Though one could argue that it’s just a clearer way to write an
interpreter from the start.

With Haskell’s syntactic sugar for unit and bind, the cost is not that
great (though there’s still some mode switching required “I have to
`return` because it expects a monad”).

** The `lift` uglyness
When using multiple State monad transformers, you must use `lift` to
access the state you want from the monad stack.  The stack order
/matters/, but it should not.

Ismael tells me there are workarounds, a library that allows you to
name the monad transformers and access them by name instead of using
lift (I guess it does the lifting for you).

If there are no hidden costs or restrictions, then this is not a
downside anymore.

** Limitations for extending cases for pattern matching
You can’t just extend functions with additional cases, since
functions are closed at definition time.

For instance, adding the evaluation of a new `Facet` AST node requires
adding a new case to `interp`.

#+BEGIN_SRC haskell
interp (Facet p t1 t2) e =
  do vH <- interp t1 e
     vL <- interp t2 e
     return (FacetV p vH vL)
#+END_SRC

But this can’t be done in another file, even though Haskell allows you
to write non-exhaustive functions ...

Using Ismael’s AOP library for Haskell, you can work around it, though
it requires some additional rewriting of the code for technical
reasons (supposedly this could be hidden by sugar).

In any case, you lose the ability to write your extensions *like you
would write* the original code.

This problem seems solved by [[http://web.cecs.pdx.edu/~mpj/pubs/modinterp.html][Monads Transformers and Modular
Interpreters]].  It is also definitely solved by [[http://www.andres-loeh.de/OpenDatatypes.pdf][Open Data Types and
Open Functions]].

The latter also allows you to think of open data type extensions as
one monolithic data type (semantically equivalent).  Except when
textual order of constructors matter.

** Can’t easily extend the data types either
To add a new AST node, you need to:

1. Extend the `Term` data type
2. Add a new case to `interp` for this new Term

Here again, the data type definition is closed.  No reflection
mechanisms to extend it?  Are there workarounds?

[[http://web.cecs.pdx.edu/~mpj/pubs/modinterp.html][Monads Transformers and Modular Interpreters]] define OR types for this
purpose.  It does not feel very natural to write, but at least if the
mechanism is there, we could hide it with sugar.

[[http://www.andres-loeh.de/OpenDatatypes.pdf][Open Data Types and Open Functions]] solves the problem in a modular
way: extensions to the data type can happen in other modules.

* Facets as a monad
If the instrumentation of the interpreter was entirely confined to a
monad, it would be the epitome of modularity (bar the two first points
above).

Can this be achieved?  Can we embed the faceted evaluation inside a
monad?

The `FacetMonad` could hold a full interpreter with duplicated
environment, store and program counter.  But that would mean
duplicating the standard rules.  And that means having a second full
interpreter with faceted evaluation ... so you just duplicate, not
really “instrumentation in a modular fashion”.
* Opening `interp`
Suggested by Rémi.

Instead of opening each case individually, `goRef` or `goIf` and so
on, we can open `interp` directly.

#+BEGIN_SRC haskell
interp t e = goInterp # (t,e)

goInterp (Bot,e) = return Bottom
goInterp ((Con i),e) = return (Constant i)
...
#+END_SRC

If the pointcut language has an `if` construct that can match on
arguments, we can dispatch advices depending on the term argument.

I > We can use the RequirePC special pointcut. I added an example in the
I > source code.

#+BEGIN_SRC haskell
deploy (aspect (and (pcCall goInterp) (match (Ref t))) goIfAdv)
#+END_SRC

Our pointcut language does not allow us to match like this, but at the
very least we could contain advices in a `goInterpAdv` function.

#+BEGIN_SRC haskell
deploy (aspect (and (pcCall goInterp)) goInterpAdv)

goInterpAdv proceed args@((If cond thn els), e) =
  -- code for goIfAdv

-- fall through
goInterpAdv proceed = proceed
#+END_SRC

* Class types approach
Another suggestion by Rémi.

#+BEGIN_SRC haskell
interp :: Dom d => Term -> d
interp (Add l r) = myAdd (interp l) (interp r)

class Dom d where
  myAdd :: d -> d -> d

instance Dom Int where
  myAdd = +

instance Dom OddOrEven where
  myAdd = xor
#+END_SRC

Here you must generalize the interpreter, to accomodate multiple
domains.  But at least the generalization is done using types: the
overhead is minimal.  Though you still need to have indirect calls.

> Ismael: Some disadvantages of this approach are discussed in the
Open Data Types paper, in Section 6.4.

* Comments

* (Ismael): I think we should enumerate all the required changes along their nature: data type extension, new case for functions, etc. Doing a diff on the LC-standard and LC-facet files yields the following:

** Term is extended with the Facet variant
** Value is extended with the FacetV variant
** instance of Eq Value is updated with the FacetV variant
** instance of Show Value is updated with the FacetV variant
** New runM function
** New case (Facet p t1 t2) added to interp
** Case (Ref t) is modified by what it looks like an around advice
** New case (Facet p t1 t2) added to helper function deref
** In helper function assign, Case (Address a) is modified by what it looks like an around advice
** New case (FacetV p vh vl) added to helper function assign
** New case (FacetV p vh vl) added to helper function apply

I propose that the contribution of the paper is a comparison or
classification of the kinds of extensibility that are desirable for a
modular instrumentation of a monadic interpreter. For extending data
types we can use the Either approach of Hudak (or maybe both
approaches are useful), and for adding cases we use AOP. Then we
discuss the benefits/drawbacks of this approach vs the Open Data Types
and Open Functions.

What we bring to attention is that AOP is (unsurprisingly) helpful to
define "open functions". Whereas the approach of Open Data... is less
expressive because it lacks a pointcut language (or something along
these lines).

* Comparing LC-facets with LC.hs

** Term is extended with the Facet variant
** Value is extended with the FacetV variant
** instance of Eq Value is updated with the FacetV variant
** instance of Show Value is updated with the FacetV variant
** New type M, now using AOT
** New runM function, where all aspects are deployed
** New case (Facet p t1 t2) added to helper function deref
** In interp: Case (Ref t) is refactored adding a goRef function which is open to weaving
** Similar change for deref function.
** Similar change for assing function.
** It would be more symmetric if all introductions of # were at the same level, e.g. at the interpreter.
** Same change for apply

Ismael >

A conclusion for this simple analysis is that to add new cases to
interp we also need to make it advisable, following Rèmi's suggestion
outlined above. In other words, if we allow for new variants to Term,
we *need* an open interp. I think this is not mutually exclusive with
the goFoo pattern, because when extending some behavior we actually
require access to the default implementation (e.g. in the (Ref t)
case, we need proceed to refer to the goRef default implementation).

Maybe this highlights the need for an extension of the pointcut
language: to be able to target a function with a specific case, while
still being able to refer to the default implementation by using
proceed. Actually this can be done using RequirePC:

* See file LC-ismael.hs

* Using RequirePC to advice a particular case of goInterp

#+BEGIN_SRC haskell
-- Require PC for Ref case
refPC :: Typeable1Monad m => RequirePC m (Term, Environment) b
refPC = RequirePC $ return (\ jp -> case unsafeCoerce jp of
                               (Jp _ _ ((Ref t, _))) -> return True
                               _ -> return False)

-- note the unsafeCoerce is actually safe because... *read TAOSD paper Section 4.1* 

-- i13n
runM :: M Value -> ProgCounter -> Store -> ((Value, ProgCounter), Store)
runM m pc s = runIdentity (runStateT (runStateT (runAOT prog) pc) s)
 where prog = do
           -- deploy (aspect (pcCall goRef) goRefAdv)       -- i13n
           deploy (aspect (pcAnd (pcCall goInterp) refPC) goRefAdv) 
           deploy (aspect (pcCall goDeref) goDerefAdv)   -- i13n
           deploy (aspect (pcCall goAssign) goAssignAdv) -- i13n
           deploy (aspect (pcCall goApply) goApplyAdv)   -- i13n
           m
#+END_SRC

* More comments: To me, the "epitome of modularity" would being able to something like what is sketched in LC-ismael-ideal.hs. It seems this can be achieved using some kind of generative programming. See comments in that file for the issues I've encountered so far...




